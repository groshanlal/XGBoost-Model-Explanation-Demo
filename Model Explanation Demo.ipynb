{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3e9043-e702-4a3a-9731-7816eacfbe4f",
   "metadata": {},
   "source": [
    "# Train a XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0ab07-3fbb-49e0-8e43-17252fc0dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_adult_income_data, get_adult_income_features, get_adult_income_feature_category_mapping\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_adult_income_data()\n",
    "feature_names, label_name = get_adult_income_features()\n",
    "feature_mapping = get_adult_income_feature_category_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8247f3-a993-4a8b-b8f2-e05b57ea1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "print(\"Training XGBoost Model\")\n",
    "model = GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79628d2f-0b1e-4a43-a5e0-0054371db0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Accuracy:\", model.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c753063-3203-4e92-a2de-cb358afc92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_model_auc\n",
    "\n",
    "print(\"Train AUC:\", get_model_auc(model, x_train, y_train))\n",
    "print(\"Test AUC:\", get_model_auc(model, x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3c4d8-66ee-40f7-985c-7b3fe76a9982",
   "metadata": {},
   "source": [
    "# Explain the XGBoost Model using TE2Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c4634-32de-4f8f-ade3-d94ce9e13294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import te2rules\n",
    "from te2rules.explainer import ModelExplainer\n",
    "print(\"Using TE2Rules version:\", te2rules.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9b5b5-b3c1-462a-9489-2eeefb6a367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainer = ModelExplainer(model=model, feature_names=feature_names)\n",
    "\n",
    "num_train = int(0.1 * len(x_train))\n",
    "rules = model_explainer.explain(X=x_train[:num_train], y=y_train_pred[:num_train], num_stages=2)\n",
    "longer_rules = model_explainer.rule_builder.longer_rules\n",
    "\n",
    "print()\n",
    "print(\"Found\", len(rules), \"rules\")\n",
    "print(\"Found\", len(longer_rules), \"longer rules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186612a-7484-41ea-b0be-61da304088e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fidelity of explanations\")\n",
    "overall, positives, negatives = model_explainer.get_fidelity(X=x_train, y=y_train_pred)\n",
    "print(\"Fidelity on positives in Train:\", positives)\n",
    "overall, positive, negative = model_explainer.get_fidelity(X=x_test, y=y_test_pred)\n",
    "print(\"Fidelity on positives in Test:\", positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265816cd-3ca9-429e-9029-13f71e03cc2e",
   "metadata": {},
   "source": [
    "## Global Model Explanation: \n",
    "### Rules to explain the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdde72d-1914-4b03-95e4-d31b0a0f514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Global Explanations of the model\")\n",
    "for i in range(len(rules)):\n",
    "    print(\"Rule\", i, \":\", rules[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62994c8f-cbef-4aa7-b602-c2cb0ee06504",
   "metadata": {},
   "source": [
    "## Explaining a Positive Instance Locally: \n",
    "### Why did the model give positive prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7554d6-01f2-43f7-93c9-6eaceb447373",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_positives = []\n",
    "x_negatives = []\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test_pred[i] == 1):\n",
    "        x_positives.append(x_test[i])\n",
    "    else:\n",
    "        x_negatives.append(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0369a-b0f3-49f6-8322-490124d67c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_most_interpretable_rules, display_input\n",
    "print(\"Local Explanations of a particular model decision\")\n",
    "\n",
    "selected_rules = model_explainer.explain_instance_with_rules(x_positives, explore_all_rules = True)\n",
    "selected_rules = get_most_interpretable_rules(selected_rules, model_explainer.longer_rules, feature_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6edaa-2d49-4bfd-9e44-1a5decc76b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explaining positive model prediction\")\n",
    "display_input(x_positives[1], feature_names, feature_mapping)\n",
    "print()\n",
    "print(\"Prediction:\", 1)\n",
    "print()\n",
    "print(\"Reason:\")\n",
    "explanation = selected_rules[1]\n",
    "for i in range(len(explanation)):\n",
    "    print(\"Rule\", i+1, \":\", explanation[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce445b-eddf-4ecb-b6a4-94f2290652b5",
   "metadata": {},
   "source": [
    "## Counterfactual explanation for a Negative Instance: \n",
    "### What needs to change in input to change model prediction to positive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a639e3-bed7-4be6-9946-63bed799c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_counterfactual_explanation, display_input\n",
    "features_that_cannot_be_changed = ['marital_status', 'relationship', 'race', 'sex', 'native_country', 'age']\n",
    "\n",
    "counterfactuals = get_counterfactual_explanation(\n",
    "                                        [x_negatives[1]], \n",
    "                                        feature_names, \n",
    "                                        features_that_cannot_be_changed,\n",
    "                                        model_explainer.longer_rules)\n",
    "\n",
    "print(\"Counterfactual explanation for negative model prediction\")\n",
    "display_input(x_negatives[1], feature_names, feature_mapping)\n",
    "print()\n",
    "print(\"Prediction:\", 0)\n",
    "print()\n",
    "print(\"Counterfactual Explanations: Satisfying any one of these is enough for making the model give a positive label\")\n",
    "for i in range(len(counterfactuals)):\n",
    "    print(\"Rule\", i+1, \":\", counterfactuals[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d36fc22-584d-4a20-ba6b-30f85ec751e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573eb18f-67c5-4087-8eba-1aeb5b7327a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a43606-d20b-4fd9-8263-5119ffbc3259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
